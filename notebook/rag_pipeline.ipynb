{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/porsche-2/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sentence_transformers import util\n",
    "from peft import PeftModel\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from safetensors.torch import load_file\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "import faiss\n",
    "from langchain_community.document_loaders import PyMuPDFLoader, PyPDFLoader, PyPDFium2Loader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "from langchain.prompts.chat import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some custom definition you need to define here.\n",
    "1. `model_name`: mode repo from hugging face \n",
    "2. `query_prompt_name`: optional, only needed for stella model\n",
    "3. `model_path`: the saved fine-tuned model path\n",
    "4. `dense_path`: the saved weights of adapter layers in the fine-tuned model\n",
    "5. `faiss_db_path`: the vector database stored location\n",
    "6. `output_json_fp`: the llm response output json filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"dunzhang/stella_en_400M_v5\"\n",
    "llm_model_name = \"tiiuae/falcon-7b-instruct\"\n",
    "query_prompt_name = \"s2p_query\"\n",
    "model_path = \"../models/stella_en_400M_v5/finetune_pair_2025-01-02_22-18-08\"\n",
    "dense_path = \"../models/stella_en_400M_v5/finetune_pair_2025-01-02_22-18-08/2_Dense/model.safetensors\"\n",
    "faiss_db_path = \"../vector_database/faiss_stella_triplet\"\n",
    "device = \"mps\"\n",
    "output_json_fp = '../results/llm_result.json'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_query = \"Could you explain the key differences in performance and handling across Porsche’s models, such as the Macan, Cayenne, 911, and Taycan? I’d like to understand how they cater to different driving styles and purposes.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Embedding Model and VectorDatabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dunzhang/stella_en_400M_v5 were not used when initializing NewModel: ['new.pooler.dense.bias', 'new.pooler.dense.weight']\n",
      "- This IS expected if you are initializing NewModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing NewModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Linear(in_features=1024, out_features=1024, bias=True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModel.from_pretrained(model_name,\n",
    "                            trust_remote_code=True, \n",
    "                            device_map=device,\n",
    "                            use_memory_efficient_attention=False,\n",
    "                            unpad_inputs=False)\n",
    "\n",
    "lora_model = PeftModel.from_pretrained(model, model_path)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path,\n",
    "                            trust_remote_code=True,  \n",
    "                            device_map=device,\n",
    "                            use_memory_efficient_attention=False,\n",
    "                            unpad_inputs=False)\n",
    "\n",
    "vector_linear = torch.nn.Linear(in_features=lora_model.config.hidden_size, out_features=1024)\n",
    "vector_linear_dict = {\n",
    "    k.replace(\"linear.\", \"\"): v for k, v in\n",
    "    load_file(dense_path).items()\n",
    "}\n",
    "vector_linear.load_state_dict(vector_linear_dict)\n",
    "vector_linear.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text, iTokenizer, iModel, iVector):\n",
    "    with torch.no_grad():\n",
    "        input_data = iTokenizer(text, padding=\"longest\", truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "        input_data = {k: v.to(device) for k, v in input_data.items()}\n",
    "        attention_mask = input_data[\"attention_mask\"]\n",
    "        last_hidden_state = iModel(**input_data)[0]\n",
    "        last_hidden = last_hidden_state.masked_fill(~attention_mask[..., None].bool(), 0.0)\n",
    "        query_vectors = last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]\n",
    "        query_vectors = normalize(iVector(query_vectors).cpu().numpy())\n",
    "        return query_vectors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_template(context, query):\n",
    "    SYSTEM_MESSAGE = \"\"\"\n",
    "        System: Here is some important context which can help inform the questions the Human asks.\n",
    "        Make sure to not make anything up to answer the question if it is not provided in the context.\n",
    "\n",
    "        Context: {}\n",
    "\n",
    "        \"\"\".format(context)\n",
    "    HUMAN_MESSAGE = \"Human: {}\".format(query)\n",
    "\n",
    "    prompt = SYSTEM_MESSAGE + HUMAN_MESSAGE + \"\\nAnswer:\"\n",
    "\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n"
     ]
    }
   ],
   "source": [
    "vector_store = FAISS.load_local(\n",
    "    faiss_db_path, \n",
    "    lambda texts: get_embedding(texts, tokenizer, lora_model, vector_linear), \n",
    "    allow_dangerous_deserialization=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/porsche-2/lib/python3.13/site-packages/transformers/modeling_utils.py:1161: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "search_results = vector_store.similarity_search(human_query, k=3)\n",
    "context_string = '\\n\\n'.join([f'Document {ind+1}: ' + i.page_content for ind, i in enumerate(search_results)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        System: Here is some important context which can help inform the questions the Human asks.\n",
      "        Make sure to not make anything up to answer the question if it is not provided in the context.\n",
      "\n",
      "        Context: Document 1: 32 Drive and chassis\n",
      "Porsche Stability Management (PSM). \n",
      "PSM is an automatic control system for maintaining \n",
      "stability at the limits of dynamic driving performance. \n",
      "Sensors continuously monitor the direction, speed, \n",
      "yaw velocity, and lateral acceleration of the car. \n",
      "Using this information, PSM calculates the actual \n",
      "direction of travel at any given moment and applies \n",
      "selective braking on individual wheels to help restore \n",
      "stability. When accelerating on road surfaces with \n",
      "varying grip, PSM improves traction using the \n",
      "Automatic Brake Dierential (ABD) system and \n",
      "Anti-Slip Regulation (ASR), providing a high level \n",
      "of driving stability and safety—and extraordinary \n",
      "agility at the same time.\n",
      "Porsche Active Suspension Management (PASM). \n",
      "Standard on all 911 models, PASM is an electronic \n",
      "damping control system that actively and continuously \n",
      "adjusts the damping force on each wheel, based on \n",
      "current road conditions and driving style, for reduced\n",
      "\n",
      "Document 2: forces. All systems communicate with one another and are optimally tuned to one another taking key \n",
      "racing considerations into account. \n",
      "The Porsche Active Suspension Management (PASM) system adjusts the damper force at each indi\u0002vidual wheel based on parameters developed specifically for the 911 GT2 RS. The driver can choose \n",
      "between two programs. Normal mode is designed for sporty driving on public roads and race tracks in \n",
      "the wet. Sport mode adjusts the damper forces for maximum lateral acceleration and the best pos\u0002sible traction on the race track. \n",
      "Depending on the speed plus the driving and steering situation, the rear-axle steering system simul\u0002taneously increases stability or agility. The characteristics of these properties have also been tuned \n",
      "with sportiness in mind. At low speeds, the system steers the rear wheels in the opposite direction \n",
      "to the turned front wheels. Tight bends can be driven through more dynamically, increasing agility. In\n",
      "\n",
      "Document 3: 40 Drive and chassis\n",
      "With the mode switch dial on the steering wheel \n",
      "you can choose from ve driving modes: Normal, \n",
      "SPORT, SPORT PLUS, WET, and Individual—allowing \n",
      "you to adapt the vehicle even more to your personal \n",
      "driving style.\n",
      "In SPORT mode, the 911 responds more dynamically. \n",
      "In SPORT PLUS mode, Porsche Active Suspension \n",
      "Management (PASM), optional Porsche Dynamic \n",
      "Chassis Control (PDCC), and rear axle steering \n",
      "ensure sportier damping, increased roll stability, \n",
      "and more direct turn-in when entering corners.\n",
      "In addition, the Sport Chrono Package has three \n",
      "more functions. Launch Control can be used to \n",
      "achieve the best possible standing start in SPORT \n",
      "PLUS mode.\n",
      "In the motorsport-derived gearshi mode, PDK \n",
      "is geared up for extremely short shi times and \n",
      "optimum shi points for maximum acceleration \n",
      "and uncompromising performance ideal for the \n",
      "race track with noticeably active gearshis. \n",
      "The SPORT Response function is activated using\n",
      "\n",
      "        Human: Could you explain the key differences in performance and handling across Porsche’s models, such as the Macan, Cayenne, 911, and Taycan? I’d like to understand how they cater to different driving styles and purposes.\n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "promt_text = prompt_template(context_string, human_query)\n",
    "print(promt_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import transformers\n",
    "import torch\n",
    "\n",
    "llm_tokenizer = AutoTokenizer.from_pretrained(llm_model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: You are currently loading Falcon using legacy code contained in the model repository. Falcon has now been fully ported into the Hugging Face transformers library. For the most up-to-date and high-performance version of the Falcon model code, please update to the latest version of transformers and then load the model without the trust_remote_code=True argument.\n",
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:46<00:00, 23.02s/it]\n"
     ]
    }
   ],
   "source": [
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=llm_model_name,\n",
    "    tokenizer=llm_tokenizer,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True,\n",
    "    device_map=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "sequences = pipeline(\n",
    "    promt_text,\n",
    "    max_length=1200,\n",
    "    do_sample=True,\n",
    "    top_k=3,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=llm_tokenizer.eos_token_id,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save result to output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: \n",
      "        System: Here is some important context which can help inform the questions the Human asks.\n",
      "        Make sure to not make anything up to answer the question if it is not provided in the context.\n",
      "\n",
      "        Context: Document 1: 32 Drive and chassis\n",
      "Porsche Stability Management (PSM). \n",
      "PSM is an automatic control system for maintaining \n",
      "stability at the limits of dynamic driving performance. \n",
      "Sensors continuously monitor the direction, speed, \n",
      "yaw velocity, and lateral acceleration of the car. \n",
      "Using this information, PSM calculates the actual \n",
      "direction of travel at any given moment and applies \n",
      "selective braking on individual wheels to help restore \n",
      "stability. When accelerating on road surfaces with \n",
      "varying grip, PSM improves traction using the \n",
      "Automatic Brake Dierential (ABD) system and \n",
      "Anti-Slip Regulation (ASR), providing a high level \n",
      "of driving stability and safety—and extraordinary \n",
      "agility at the same time.\n",
      "Porsche Active Suspension Management (PASM). \n",
      "Standard on all 911 models, PASM is an electronic \n",
      "damping control system that actively and continuously \n",
      "adjusts the damping force on each wheel, based on \n",
      "current road conditions and driving style, for reduced\n",
      "\n",
      "Document 2: forces. All systems communicate with one another and are optimally tuned to one another taking key \n",
      "racing considerations into account. \n",
      "The Porsche Active Suspension Management (PASM) system adjusts the damper force at each indi\u0002vidual wheel based on parameters developed specifically for the 911 GT2 RS. The driver can choose \n",
      "between two programs. Normal mode is designed for sporty driving on public roads and race tracks in \n",
      "the wet. Sport mode adjusts the damper forces for maximum lateral acceleration and the best pos\u0002sible traction on the race track. \n",
      "Depending on the speed plus the driving and steering situation, the rear-axle steering system simul\u0002taneously increases stability or agility. The characteristics of these properties have also been tuned \n",
      "with sportiness in mind. At low speeds, the system steers the rear wheels in the opposite direction \n",
      "to the turned front wheels. Tight bends can be driven through more dynamically, increasing agility. In\n",
      "\n",
      "Document 3: 40 Drive and chassis\n",
      "With the mode switch dial on the steering wheel \n",
      "you can choose from ve driving modes: Normal, \n",
      "SPORT, SPORT PLUS, WET, and Individual—allowing \n",
      "you to adapt the vehicle even more to your personal \n",
      "driving style.\n",
      "In SPORT mode, the 911 responds more dynamically. \n",
      "In SPORT PLUS mode, Porsche Active Suspension \n",
      "Management (PASM), optional Porsche Dynamic \n",
      "Chassis Control (PDCC), and rear axle steering \n",
      "ensure sportier damping, increased roll stability, \n",
      "and more direct turn-in when entering corners.\n",
      "In addition, the Sport Chrono Package has three \n",
      "more functions. Launch Control can be used to \n",
      "achieve the best possible standing start in SPORT \n",
      "PLUS mode.\n",
      "In the motorsport-derived gearshi mode, PDK \n",
      "is geared up for extremely short shi times and \n",
      "optimum shi points for maximum acceleration \n",
      "and uncompromising performance ideal for the \n",
      "race track with noticeably active gearshis. \n",
      "The SPORT Response function is activated using\n",
      "\n",
      "        Human: Could you explain the key differences in performance and handling across Porsche’s models, such as the Macan, Cayenne, 911, and Taycan? I’d like to understand how they cater to different driving styles and purposes.\n",
      "Answer: The <strong>F-word</strong> (F-word, <strong>F-word, F word) is the most important word of the year 2017. It is a word that has been used in the past to describe a person who is a <strong>F-word</strong> (F-word) and is now being used to describe a <strong>F-word</strong> (F-word, F word). It has been used in a number of different contexts, from the <strong>F-word</strong> (F-word, F word) to <strong>F-word</strong> (F-word, F word) in a <strong>F-word (F-word, F word). The word is used to refer to the <strong>F-word (F-word, F word)</strong> (F-word, <strong>F word</strong>), but it can also be used to describe the <strong>F-word (F-word, F word)</strong> (F-word, F word) itself.\n",
      "\n",
      "The <strong>F-word (F-word, F word)</strong> (F-word, <strong>F word</strong>) is a word that has been used in the past to describe a <strong>F-word (F-word, F word)</strong> (F-word, <strong>F word</strong>) and is now being used to describe the <strong>F-word (F-word, F word)</strong> (F-word\n"
     ]
    }
   ],
   "source": [
    "for seq in sequences:\n",
    "    print(f\"Result: {seq['generated_text']}\")\n",
    "\n",
    "import json\n",
    "content = []\n",
    "with open(output_json_fp, 'r') as f:\n",
    "    try:\n",
    "        content = json.load(f, content)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "with open(output_json_fp, 'w') as f:\n",
    "    content.append(\n",
    "        {\n",
    "            \"question\": human_query,\n",
    "            \"response\": sequences[0]['generated_text'].replace(promt_text, '')\n",
    "        }\n",
    "    )\n",
    "\n",
    "    json.dump(content, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "porsche-2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
