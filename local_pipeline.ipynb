{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Embedding Model and VectorDatabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/porsche-2/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sentence_transformers import util\n",
    "from peft import PeftModel\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from safetensors.torch import load_file\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "import faiss\n",
    "from langchain_community.document_loaders import PyMuPDFLoader, PyPDFLoader, PyPDFium2Loader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "from langchain.prompts.chat import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_prompt_name = \"s2p_query\"\n",
    "model_path = \"models/stella_en_400M_v5/finetune_triplets_2025-01-02_18-06-49\"\n",
    "dense_path = \"models/stella_en_400M_v5/finetune_triplets_2025-01-02_18-06-49/2_Dense/model.safetensors\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dunzhang/stella_en_400M_v5 were not used when initializing NewModel: ['new.pooler.dense.bias', 'new.pooler.dense.weight']\n",
      "- This IS expected if you are initializing NewModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing NewModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Linear(in_features=1024, out_features=1024, bias=True)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModel.from_pretrained(\"dunzhang/stella_en_400M_v5\",\n",
    "                            trust_remote_code=True, \n",
    "                            device_map='mps',\n",
    "                            use_memory_efficient_attention=False,\n",
    "                            unpad_inputs=False)\n",
    "\n",
    "lora_model = PeftModel.from_pretrained(model, model_path)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path,\n",
    "                            trust_remote_code=True,  \n",
    "                            device_map='mps',\n",
    "                            use_memory_efficient_attention=False,\n",
    "                            unpad_inputs=False)\n",
    "\n",
    "vector_linear = torch.nn.Linear(in_features=lora_model.config.hidden_size, out_features=1024)\n",
    "vector_linear_dict = {\n",
    "    k.replace(\"linear.\", \"\"): v for k, v in\n",
    "    load_file(dense_path).items()\n",
    "}\n",
    "vector_linear.load_state_dict(vector_linear_dict)\n",
    "vector_linear.to(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text, iTokenizer, iModel, iVector):\n",
    "    with torch.no_grad():\n",
    "        input_data = iTokenizer(text, padding=\"longest\", truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "        input_data = {k: v.to(\"mps\") for k, v in input_data.items()}\n",
    "        attention_mask = input_data[\"attention_mask\"]\n",
    "        last_hidden_state = iModel(**input_data)[0]\n",
    "        last_hidden = last_hidden_state.masked_fill(~attention_mask[..., None].bool(), 0.0)\n",
    "        query_vectors = last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]\n",
    "        query_vectors = normalize(iVector(query_vectors).cpu().numpy())\n",
    "        return query_vectors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_template(context, query):\n",
    "    SYSTEM_MESSAGE = \"\"\"\n",
    "        System: Here is some important context which can help inform the questions the Human asks.\n",
    "        Make sure to not make anything up to answer the question if it is not provided in the context.\n",
    "\n",
    "        Context: {}\n",
    "\n",
    "        \"\"\".format(context)\n",
    "    HUMAN_MESSAGE = \"Human: {}\".format(query)\n",
    "\n",
    "    prompt = SYSTEM_MESSAGE + HUMAN_MESSAGE\n",
    "\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n"
     ]
    }
   ],
   "source": [
    "vector_store = FAISS.load_local(\n",
    "    \"vector_database/faiss_stella\", \n",
    "    lambda texts: get_embedding(texts, tokenizer, lora_model, vector_linear), \n",
    "    allow_dangerous_deserialization=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_query = \"I am new to Porsche. Which model should I have?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/porsche-2/lib/python3.13/site-packages/transformers/modeling_utils.py:1161: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "search_results = vector_store.similarity_search(human_query, k=3)\n",
    "context_string = '\\n\\n'.join([f'Document {ind+1}: ' + i.page_content for ind, i in enumerate(search_results)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        System: Here is some important context which can help inform the questions the Human asks.\n",
      "        Make sure to not make anything up to answer the question if it is not provided in the context.\n",
      "\n",
      "        Context: Document 1: 4 The dream of the sports car 6 Porsche Codes\n",
      "10 718 Cayman & 718 Boxster\n",
      "16 718 Cayman GT4\n",
      "22 718 Cayman GT4 RS\n",
      "28 718 Spyder\n",
      "34 911 Carrera & 911 Targa\n",
      "40 911 Turbo\n",
      "46 911 GT3\n",
      "52 Taycan\n",
      "58 Panamera\n",
      "64 Macan\n",
      "70 Cayenne\n",
      "78 Porsche Exclusive Manufaktur\n",
      "82 Porsche Tequipment & \n",
      "Porsche Car Configurator\n",
      "86 Specifications\n",
      "\n",
      "Document 2: 30 Models\n",
      "| 718 31\n",
      "Six-cylinder naturally aspirated boxer engine\n",
      "Porsche Doppelkupplung (PDK) \n",
      "or manual transmission\n",
      "Rear-wheel drive\n",
      "Lightweight convertible top\n",
      "Two seats\n",
      "Two luggage \n",
      "compartments\n",
      "Adaptive GT sports suspension\n",
      "GT brake system\n",
      "Mid-engine concept\n",
      "For efficiency class, fuel consumption and CO₂ emissions, please refer to page 86 onwards.\n",
      "\n",
      "Document 3: 48 Models\n",
      "| 911 49\n",
      "Six-cylinder high-revving naturally aspirated engine\n",
      "With a rigid rear wing or with the\n",
      "Touring Package (without rear wing)\n",
      "Race track chassis\n",
      "Rear-wheel drive\n",
      "Porsche Doppelkupplung (PDK) \n",
      "or manual transmission\n",
      "Lightweight construction concept\n",
      "For efficiency class, fuel consumption and CO₂ emissions, please refer to page 86 onwards.\n",
      "Two seats\n",
      "Luggage compartment, front\n",
      "\n",
      "        Human: I am new to Porsche. Which model should I have?\n"
     ]
    }
   ],
   "source": [
    "promt_text = prompt_template(context_string, human_query)\n",
    "print(promt_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import transformers\n",
    "import torch\n",
    "\n",
    "model = \"tiiuae/falcon-7b-instruct\"\n",
    "\n",
    "llm_tokenizer = AutoTokenizer.from_pretrained(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: You are currently loading Falcon using legacy code contained in the model repository. Falcon has now been fully ported into the Hugging Face transformers library. For the most up-to-date and high-performance version of the Falcon model code, please update to the latest version of transformers and then load the model without the trust_remote_code=True argument.\n",
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:34<00:00, 17.48s/it]\n"
     ]
    }
   ],
   "source": [
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=llm_tokenizer,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True,\n",
    "    device_map=\"mps\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "sequences = pipeline(\n",
    "    promt_text,\n",
    "    max_length=500,\n",
    "    do_sample=False,\n",
    "    top_k=3,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=llm_tokenizer.eos_token_id,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: \n",
      "        System: Here is some important context which can help inform the questions the Human asks.\n",
      "        Make sure to not make anything up to answer the question if it is not provided in the context.\n",
      "\n",
      "        Context: Document 1: 4 The dream of the sports car 6 Porsche Codes\n",
      "10 718 Cayman & 718 Boxster\n",
      "16 718 Cayman GT4\n",
      "22 718 Cayman GT4 RS\n",
      "28 718 Spyder\n",
      "34 911 Carrera & 911 Targa\n",
      "40 911 Turbo\n",
      "46 911 GT3\n",
      "52 Taycan\n",
      "58 Panamera\n",
      "64 Macan\n",
      "70 Cayenne\n",
      "78 Porsche Exclusive Manufaktur\n",
      "82 Porsche Tequipment & \n",
      "Porsche Car Configurator\n",
      "86 Specifications\n",
      "\n",
      "Document 2: 30 Models\n",
      "| 718 31\n",
      "Six-cylinder naturally aspirated boxer engine\n",
      "Porsche Doppelkupplung (PDK) \n",
      "or manual transmission\n",
      "Rear-wheel drive\n",
      "Lightweight convertible top\n",
      "Two seats\n",
      "Two luggage \n",
      "compartments\n",
      "Adaptive GT sports suspension\n",
      "GT brake system\n",
      "Mid-engine concept\n",
      "For efficiency class, fuel consumption and CO₂ emissions, please refer to page 86 onwards.\n",
      "\n",
      "Document 3: 48 Models\n",
      "| 911 49\n",
      "Six-cylinder high-revving naturally aspirated engine\n",
      "With a rigid rear wing or with the\n",
      "Touring Package (without rear wing)\n",
      "Race track chassis\n",
      "Rear-wheel drive\n",
      "Porsche Doppelkupplung (PDK) \n",
      "or manual transmission\n",
      "Lightweight construction concept\n",
      "For efficiency class, fuel consumption and CO₂ emissions, please refer to page 86 onwards.\n",
      "Two seats\n",
      "Luggage compartment, front\n",
      "\n",
      "        Human: I am new to Porsche. Which model should I have?\n",
      "\n",
      "As an AI language model, I cannot provide personal recommendations. However, I can provide you with some information to help you make an informed decision.\n",
      "\n",
      "The 911 is a classic and iconic model that has been around for decades. It is a two-door sports car that is known for its performance and handling. It is also a more practical option compared to the Boxster, as\n"
     ]
    }
   ],
   "source": [
    "for seq in sequences:\n",
    "    print(f\"Result: {seq['generated_text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "porsche-2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
